""version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOO_4LW_COMMANDS_WHITELIST: ruok, mntr, conf, srvr, stat
    ports:
      - "2181:2181"
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    networks:
      - kafka-network

  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      SPARK_MODE: master
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - kafka-network

networks:
  kafka-network:
    driver: bridge

# Instrukcje uruchomienia:
# 1. Uruchomienie środowiska:
#    docker-compose up -d
#
# 2. Stworzenie topica 'transactions':
#    docker exec -it kafka kafka-topics --create --topic transactions --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
#
# 3. Produkcja wiadomości:
#    docker exec -it kafka kafka-console-producer --topic transactions --bootstrap-server localhost:9092
#
# 4. Konsumpcja wiadomości:
#    docker exec -it kafka kafka-console-consumer --topic transactions --bootstrap-server localhost:9092 --from-beginning
#
# Spark UI dostępne pod: http://localhost:8080
# Spark Master pod adresem: spark://localhost:7077
""
